{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/drive/1_7ZERbrfywPfYD4pPOh6PNoDqQ-0Yq8D?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random number generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://cdn.ablebits.com/_img-blog/random-generator/random-generator.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which properties should a good random number generator have?\n",
    "* must be able to generate numbers that are uniformly distributed in [0, 1]\n",
    "* pass statistical tests (which ones?)\n",
    "* high speed of generation\n",
    "* large period\n",
    "* it works on any platform\n",
    "* reproducibility\n",
    "* cryptographic security (whether this is consistent with previous punctuations?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random number generator is an **deterministic** (!) algorithm that generates a sequence of numbers that meet certain statistical requirements for randomness. The sequence is not truly random in that it is completely determined by an initial value, called the seed. The same sequence of numbers is generated from the same seed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Middle-square algorithm\n",
    "John von Neumann, 1949\n",
    "\n",
    "Ideas:\n",
    "1. set a four-digit seed - the first number of the random sequence\n",
    "2. square it, get an 8-digit number (if necessary, pad with zeros)\n",
    "3. take a four-digit number from the middle - this is the next element of the random sequence\n",
    "4. repeat 2-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5497, 2170, 7089, 2539, 4465, 9362, 6470, 8609, 1148, 3179, 1060,\n",
       "       1236, 5276, 8361, 9063, 1379, 9016, 2882, 3059, 3574, 7734, 8147,\n",
       "       3736, 9576, 6997, 9580, 7764, 2796, 8176, 8469, 7239, 4031, 2489,\n",
       "       1951, 8064,  280,  784, 6146, 7733, 7992, 8720,  384, 1474, 1726,\n",
       "       9790, 8441, 2504, 2700, 2900, 4100, 8100, 6100, 2100, 4100, 8100,\n",
       "       6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100,\n",
       "       8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100,\n",
       "       4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100,\n",
       "       2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100,\n",
       "       6100, 2100])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def midsquare(val, n=4):\n",
    "    return int(str(val**2).zfill(2*n)[n//2:-n//2])\n",
    "\n",
    "seed = 5497\n",
    "seq = [seed]\n",
    "for _ in range(100):\n",
    "    seq.append(midsquare(seq[-1]))\n",
    "np.array(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "… random numbers should not be\n",
    "generated with a method chosen at\n",
    "random. Some theory should be\n",
    "used.\n",
    "```\n",
    "D. Knuth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear congruential generator (LCG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear congruential generator (LCG) is an algorithm that yields a sequence of pseudo-randomized numbers calculated with a discontinuous piecewise linear equation. The method represents one of the oldest and best-known pseudorandom number generator algorithms. The theory behind them is relatively easy to understand, and they are easily implemented and fast, especially on computer hardware which can provide modulo arithmetic by storage-bit truncation.\n",
    "$$ z_{i+1} = (az_i + c) \\mod m $$\n",
    "\n",
    "A number $z_0$ called the **seed**. It makes the sequence reproducible.\n",
    "\n",
    "Let's implement LCG and test it (on practice it is implemented a little bit complicated, but we will use a simple version for educational purposes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rng(m=2**32, a=1103515245, c=12345):\n",
    "    rng.current = (a * rng.current + c) % m\n",
    "    return rng.current / m\n",
    "\n",
    "# setting the seed\n",
    "rng.current = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are 10 first numbers of the sequence generated by LCG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.25693503906950355,\n",
       " 0.5878706516232342,\n",
       " 0.15432575810700655,\n",
       " 0.767266943352297,\n",
       " 0.9738139626570046,\n",
       " 0.5858681506942958,\n",
       " 0.8511155843734741,\n",
       " 0.6132153405342251,\n",
       " 0.7473867232911289,\n",
       " 0.06236015981994569]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[rng() for _ in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we verify that the sequence does indeed resemble a sample from a uniform distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a larger sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [rng() for _ in range(1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first \"test\" is to plot the histogram of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.hist(samples, bins=20, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram does not seem to contradict the hypothesis of uniformity of distribution, but more accurate quantitative estimates are needed. They are obtained with the help of statistical tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Tests\n",
    "\n",
    "The general idea of statistical tests. Suppose we want to test the hypothesis that a sample $X$ belongs to some particular (very particular) distribution $F$. The problem is to come up with a statistic (a function of the sample) $T(X)$ which, if our hypothesis is true, will have (at $n\\to\\infty$) a priori known distribution, e.g. $\\mathcal{N}(0, 1)$. Let's calculate the value of the statistic $T=T(X)$ on our sample. If the obtained number $T$ is highly atypical for a normal $\\mathcal{N}(0, 1)$ distribution, we reject the hypothesis. More precisely, we calculate $p=P(|\\xi|\\ge|T|)$ for $\\xi\\sim N(0,1)$. This number $p$ has a special name: $p$-value. If it is small, e.g., less than $0.05$, it is a reason to reject the hypothesis.\n",
    "\n",
    "Next, we will discuss specific tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kolmogorov-Smirnov test\n",
    "\n",
    "We test the hypothesis that the sample is drawn from the $F$ distribution.\n",
    "Calculate the statistic\n",
    "$$T(X) = \\sup_x| F(x) - F_n(x)|,$$\n",
    "where $F_n(x)$ is the empirical distribution function constructed from a sample $X$ of size $n$.\n",
    "Essentially, $T$ is the largest distance between the two plots (see the picture below).\n",
    "\n",
    "It turns out that if the hypothesis is true, the value $\\sqrt{n}T$ has (in the limit of large $n$) a special distribution called the [Kolmogorov distribution](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D0%9A%D0%BE%D0%BB%D0%BC%D0%BE%D0%B3%D0%BE%D1%80%D0%BE%D0%B2%D0%B0).\n",
    "\n",
    "The Kolmogorov distribution is tabular, so for any value of the statistic $T$ we can find the $p$-value and see if it is small or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/c/cf/KS_Example.png/450px-KS_Example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, everything is done in one line (tests the hypothesis that the sample belongs to a uniform distribution `stats.uniform.cdf`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.026368738710880302, pvalue=0.4892115759774216)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "stats.kstest(samples, stats.uniform.cdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to interpret the results?\n",
    "\n",
    "statistic=$0.02637$ - statistic value (maximum distance between graphs)\n",
    "\n",
    "pvalue=$0.48207$ - p-value for this statistic value. We see that pvalue $> 0.05$, so we decide NOT to reject the hypothesis of a uniform distribution.\n",
    "\n",
    "For comparison, let's test the hypothesis that the sample is generated by a normal law:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.500866322716208, pvalue=0.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.kstest(samples, stats.norm.cdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the p-value is extremely small and we safely reject the hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-squared test (Pearson's chi-squared test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most popular tests. Again we test the hypothesis that the sample (of size $n$) came from the distribution $F$. The idea is to divide the whole area of definition of a random variable into $K$ intervals and in each interval to calculate how many elements of the sample fell into the given interval and how many we would expect to see there, if the sample had size n and was generated by the $F$ distribution. We compile the statistics\n",
    "$$\\chi^2_{K-1}=\\sum\\limits_{i=1}^{K}\\frac{(E_i-O_i)^2}{E_i}$$\n",
    "\n",
    "$E_i, O_i $ are the expected and observed numbers of sample items in the i-th value interval.\n",
    "\n",
    "It is recommended to choose $K$ such that $O_i, E_i \\ge 5$.\n",
    "\n",
    "If the hypothesis is true, the criterion statistic has (in the limit of large $n$) a $\\chi^2$ distribution with $K-1$ degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of the $\\chi^2$ distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([42, 49, 55, 60, 49, 38, 51, 53, 51, 50, 50, 47, 38, 47, 45, 65, 50,\n",
       "        60, 56, 44]),\n",
       " array([50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "        50, 50, 50]),\n",
       " Power_divergenceResult(statistic=18.599999999999998, pvalue=0.48275240319942647))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 20\n",
    "f_obs = np.histogram(samples, np.linspace(0, 1, k+1))[0]\n",
    "f_exp = np.full(k, len(samples) // k)\n",
    "\n",
    "f_obs, f_exp, stats.chisquare(f_obs, f_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion - the observed value of the statistic does not contradict the hypothesis of uniform distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: sequences `sorted(samples)` and `samples` are indistinguishable for $KS$ and $\\chi^2$ tests. We need additional tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serial test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: break the sequence $x_1, x_2, x_3, ..., x_{2n}$ into consecutive series of length $2$: $(x_1, x_2), (x_3, x_4), ..., (x_{2n-1}, x_{2n})$ and look at each element as a random and independent point in $2D$ space. Next, apply chi-square. Similarly, one can construct series of length $3, 4$, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "Implement serial test and apply to a `samples`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002\n",
      "Статистика хи-квадрат: 250499.99999999994\n",
      "p-значение: 0.239164620386637\n"
     ]
    }
   ],
   "source": [
    "def serial_test(samples):\n",
    "    pairs = [(samples[i], samples[i+1]) for i in range(0, len(samples)-1, 2)]\n",
    "    \n",
    "    x, y = zip(*pairs)\n",
    "    f_obs, x_edges, y_edges = np.histogram2d(x, y, bins=[np.linspace(0, 1, len(samples)//2+1), np.linspace(0, 1, len(samples)//2+1)])\n",
    "    \n",
    "    n_exp = np.sum(f_obs) / (len(x_edges)-1) / (len(y_edges)-1)\n",
    "    print(n_exp)\n",
    "    f_exp = np.full(f_obs.shape, n_exp)\n",
    "    \n",
    "    chi2_stat, p_value = stats.chisquare(f_obs.flatten(), f_exp.flatten())\n",
    "    \n",
    "    return chi2_stat, p_value\n",
    "\n",
    "chi2_stat, p_value = serial_test(samples)\n",
    "print(\"Статистика хи-квадрат:\", chi2_stat)\n",
    "print(\"p-значение:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again decompose the sequence $x_1, x_2, x_3, ..., x_{dn}$ into consecutive series of length $d$: $(x_1, ..., x_d), (x_{d+1}, x_{2d+d}), \\ldots, (x_{nd-d+1}, x_{nd})$. A series of $d$ elements can be ordered in $d!$ ways and each way of ordering is equally probable. Hence the idea of the test is to count how many times each ordering occurs among $n$ series and apply the $\\chi^2$ test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2*\n",
    "Implement permutation test and apply to a `samples`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistic: 10.0, p-value: 0.8197399195036016\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "def permutation_test(samples, d):\n",
    "    series = np.array([samples[i:i+d] for i in range(0, len(samples), d)])\n",
    "\n",
    "    permutations = np.array(list(map(tuple, np.unique(np.array([np.random.permutation(series[0]) for _ in range(np.math.factorial(d))]), axis=0))))\n",
    "\n",
    "    counts = np.array([len(series[series == permutation].flatten()) for permutation in permutations])\n",
    "    statistic, p_value = chisquare(counts)\n",
    "\n",
    "    return statistic, p_value\n",
    "\n",
    "d = 4\n",
    "statistic, p_value = permutation_test(samples, d)\n",
    "print(f'Statistic: {statistic}, p-value: {p_value}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice of parameters $m$, $a$ and $c$ has a significant impact on the quality of the sequence. If the parameters are chosen unsuccessfully, it can lead to unexpected consequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rng_bad(m=2**31, a=65539, c=0):\n",
    "    rng_bad.current = (a * rng_bad.current + c) % m\n",
    "    return rng_bad.current / m\n",
    "rng_bad.current = 1\n",
    "\n",
    "random = [rng_bad() for _ in range(30000)]\n",
    "print(\"This sequence looks as random:\")\n",
    "random[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram of the distribution is similar to a uniform distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.hist(random, 20, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the series test shows that the points are located on hyperplanes, which does not fit well with the notion of randomness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter(random[::3], random[1::3], random[2::3], s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_3d(x=random[::3], y=random[1::3], z=random[2::3], opacity=0.1)\n",
    "fig.update_traces(marker_size = 2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "Provide a statistical test to show that `rng_bad` has problems but `rng_good` does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the bad one's p value:\n",
      " 0.0016913374845818354\n",
      "the good one's p value:\n",
      " 0.2429858445693046 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def rng_bad(m = 2**31, a = 65539, c = 0):\n",
    "    \n",
    "    rng_bad.current = (a * rng_bad.current + c) % m\n",
    "    return rng_bad.current / m\n",
    "\n",
    "\n",
    "def rng_good(m = 2**32, a = 1103515245, c = 12345):\n",
    "    \n",
    "    rng_good.current = (a * rng_good.current + c) % m\n",
    "    return rng_good.current / m\n",
    "\n",
    "\n",
    "def comparing():\n",
    "    \n",
    "    k = 10\n",
    "    n = 25\n",
    "    \n",
    "    rng_bad.current = rng_good.current = 1\n",
    "\n",
    "    bad = [rng_bad() for i in range(n)]\n",
    "    good = [rng_good() for i in range(n)]\n",
    "    \n",
    "    f_obs_bad = np.histogram(bad, np.linspace(0, 1, k + 1))[0]\n",
    "    f_obs_good = np.histogram(good, np.linspace(0, 1, k + 1))[0]\n",
    "    f_exp_bad = np.full(k, len(bad) // k)\n",
    "    f_exp_good = np.full(k, len(good) // k)\n",
    "    \n",
    "    _, p_bad = stats.chisquare(f_obs_bad, f_exp_bad)\n",
    "    _, p_good = stats.chisquare(f_obs_good, f_exp_good)\n",
    "    \n",
    "    print(\"the bad one's p value:\\n\", p_bad)\n",
    "    print(\"the good one's p value:\\n\", p_good,'\\n')   \n",
    "comparing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* More randomness tests - [Diehard tests](https://en.wikipedia.org/wiki/Diehard_tests).\n",
    "* More methods for generating a uniform value [here](https://en.wikipedia.org/wiki/List_of_random_number_generators).\n",
    "* A story about dynamical systems and the transition to chaos https://www.youtube.com/watch?v=ovJcsL7vyrk&feature=youtu.be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a sample from a given distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a random number generator from the segment [0, 1] (use the `np.random.rand()` function for this). How to get a sample from another distribution $F$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "Simulate a sample of 1000 from a discrete distribution on a set of digits $0, 1, 2, \\ldots, 9$ with weights $0.12, 0.3, 0.167, 0.24, 0.31, 0.54, 0.111, 0.02, 0.001, 0.2$. Construct a histogram from the sample. Optimise the algorithm by ordering the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = np.arange(10)\n",
    "weights = np.array([0.12, 0.3, 0.167, 0.24, 0.31, 0.54, 0.111, 0.02, 0.001, 0.2])\n",
    "\n",
    "sorted_indices = np.argsort(weights)[::-1]\n",
    "digits = digits[sorted_indices]\n",
    "weights = weights[sorted_indices]\n",
    "\n",
    "sample = np.random.choice(digits, size=1000, p=weights / np.sum(weights))\n",
    "\n",
    "plt.hist(sample, bins=np.arange(11)-0.5)\n",
    "plt.xticks(digits)\n",
    "plt.xlabel('digits')\n",
    "plt.ylabel('amount of samples')\n",
    "plt.title('histogram of weights')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse transform method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following proposition is the idea behind the *inverse transform* method:\n",
    "\n",
    "If $\\xi$ has a uniform distribution in $[0,1]$, then $F^{-1}(\\xi)$ is distributed according to the law of $F$. (For which $F$ is this true?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "Simulate a sample of size 1000 from the distribution $\\operatorname{Exp}(\\lambda)$ using the Inverse transform method. Construct a sample histogram and an accurate plot of the distribution density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample():\n",
    "    \n",
    "    lambda_value = 0.5\n",
    "\n",
    "    x = np.random.uniform(0, 1, 1000)\n",
    "    samples = - np.log(1 - x) / lambda_value\n",
    "    sample_histogram(samples, lambda_value)\n",
    "\n",
    "    \n",
    "def sample_histogram(samples, lambda_value):\n",
    "    \n",
    "    plt.figure(figsize = (10, 7.5))\n",
    "\n",
    "    plt.hist(samples, bins = \"auto\", density = True, label = 'sample')\n",
    "    \n",
    "    x = np.linspace(0, 10, 1000)\n",
    "    plt.plot(x, lambda_value * np.exp(- lambda_value * x), label = 'accurate')\n",
    "    \n",
    "    plt.xlabel('value', size = 'large')\n",
    "    plt.ylabel('density', size = 'large')\n",
    "    plt.legend(loc = 'upper right', fontsize = 'large')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "get_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejection sampling (Accept-reject method)\n",
    "\n",
    "The idea of the method is to sample from the distribution we know how to sample from, and then select points that follow the desired distribution. More precisely: let's say we know how to sample from a distribution with density $p$, and we want to sample from a distribution with density $\\pi$. Let's take a random $x$ from the distribution $p$. Then take $y$ uniformly distributed on the interval $[0, p(x)]$. If the point $(x, y)$ falls under the graph of $\\pi$, we take $x$ as a sampling element from $\\pi$. If not, we repeat the procedure for a new $x$. The picture illustrates the idea of the method (the densities are normalised so that one lies entirely under the other):\n",
    "\n",
    "<img src=https://colcarroll.github.io/hamiltonian_monte_carlo_talk/images/bayes_talk.015.png style=\"width: 50%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6\n",
    "Justify (orally) that the accept-reject method really samples from the required distribution. Simulate $1000$ points from the distribution with density $e^xcos^2x$ on the segment $\\left[-\\dfrac\\pi2, \\dfrac\\pi2\\right]$. Plot the sampled histogram on the sample and compare it with the plot of the exact density function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "x = np.linspace(-np.pi/2, np.pi/2, 100)\n",
    "density = np.exp(x)*np.cos(x)**2 # not normalized density!\n",
    "plt.fill_between(x, 0, density)\n",
    "plt.ylabel('PDF (not normalized)')\n",
    "plt.xlabel('x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "\n",
    "def density(x):\n",
    "    return np.exp(x) * np.cos(x)**2\n",
    "\n",
    "\n",
    "def normalized_density(x, coef):\n",
    "    return np.exp(x) * np.cos(x)**2 / coef\n",
    "\n",
    "\n",
    "def plot():\n",
    "    \n",
    "    coef, _ = quad(density, - np.pi/2, np.pi/2)\n",
    "    v = np.random.uniform(- np.pi/2, np.pi/2, 1000)\n",
    "    u = np.random.uniform(0, 1, 1000)\n",
    "    sample = v[u < normalized_density(v, coef)]\n",
    "                  \n",
    "    plt.figure(figsize = (10, 7.5))\n",
    "    \n",
    "    plt.hist(sample, bins = \"auto\", density = True, label = 'sample')\n",
    "    \n",
    "    x = np.linspace(- np.pi/2, np.pi/2, 500)\n",
    "    plt.plot(x, normalized_density(x, coef), label = 'accurate')\n",
    "    \n",
    "    plt.xlabel('value', size = 'large')\n",
    "    plt.ylabel('density', size = 'large')\n",
    "    plt.legend(loc = 'upper right', fontsize = 'large')\n",
    "    plt.show()\n",
    "    \n",
    "plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinate transformation method\n",
    "\n",
    "The accept-reject method may in some cases be inefficient and require too many sample points. An alternative is to try to find a coordinate transformation that converts a simple area (from which it is easy to sample, for example, a unit square) into the required area, but preserves the area ratio (why?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7\n",
    "Model and depict a sample of 500 points uniformly distributed within a given triangle without using a selection method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "polygon = Polygon(xy=np.array([[1, 2], [2, 6], [8, 1]]), closed=True)\n",
    "plt.gca().add_collection(PatchCollection([polygon]))\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "trg = np.array([[1, 2], [2, 6], [8, 1]])\n",
    "fig = plt.figure()\n",
    "x = np.random.uniform(0, 1, 1000)\n",
    "y = np.random.uniform(0, 1, 1000)\n",
    "samples = []\n",
    "\n",
    "for i in range(1000):\n",
    "    if x[i] + y[i] <= 1:\n",
    "        sample = (1 - x[i] - y[i]) * trg[0] + x[i] * trg[1] + y[i] * trg[2]\n",
    "        samples.append(sample)\n",
    "        \n",
    "samples = np.array(samples)\n",
    "polygon = Polygon(xy=trg, closed=True)\n",
    "plt.gca().add_collection(PatchCollection([polygon]))\n",
    "plt.scatter(samples[:, 0], samples[:, 1], color = \"red\", s = 0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8\n",
    "Model without using the selection method a sample of $500$ points uniformly distributed inside the unit circle. Picture the obtained points. Do they really fill the circle uniformly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "t = np.linspace(0, 2 * np.pi, 100)\n",
    "plt.plot(np.sin(t), np.cos(t))\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot():\n",
    "    \n",
    "    plt.figure(figsize = (10, 10))\n",
    "    \n",
    "    r = np.sqrt(np.random.uniform(0, 1, 500))\n",
    "    phi = np.random.uniform(0, 2 * np.pi, 500)\n",
    "    plt.scatter(r * np.cos(phi), r * np.sin(phi))\n",
    "\n",
    "    t = np.linspace(0, 2 * np.pi, 100)\n",
    "    plt.plot(np.sin(t), np.cos(t))\n",
    "    plt.axis('equal') \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random normal generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9\n",
    "Prove (orally) that the following algorithm (**Box-Muller algorithm**, https://en.wikipedia.org/wiki/Box%E2%80%93Muller_transform) generates a sample of independent $\\mathcal{N}(0,1)$ random variables. Modify the method to exclude calls of trigonometric functions `np.sin` and `np.cos`. Using the modified method, simulate a sample size of $1000$ from a $2D$ Gaussian distribution with mean $\\mu$ and covariance matrix $\\Sigma$, where\n",
    "$$\\mu = \\begin{pmatrix} 4 \\\\ 7 \\end{pmatrix}^T, \\quad \\Sigma = \\begin{pmatrix} 20 & -4 \\\\ -4 & 40 \\end{pmatrix}.$$\n",
    "Construct a 2D histogram of the resulting distribution. Compare the sample mean and covariance matrix with the exact values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "u1, u2 = np.random.rand(2, n)\n",
    "r = np.sqrt(-2 * np.log(u1))\n",
    "theta = 2 * np.pi * u2\n",
    "x = r * np.cos(theta)\n",
    "y = r * np.sin(theta)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax[0].hist2d(x, y, bins=30)\n",
    "ax[0].axis('equal')\n",
    "ax[1].hist(x, bins=30)\n",
    "ax[2].hist(y, bins=30)\n",
    "ax[0].set_title(\"2d histogram\")\n",
    "ax[1].set_title(\"Histogram of x\")\n",
    "ax[2].set_title(\"Histogram of y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_muller(mean, covariance):\n",
    "    \n",
    "    u1, u2 = np.random.rand(2, 1000)\n",
    "    x, y = 2 * u1 - 1, 2 * u2 - 1\n",
    "    s = x**2 + y**2\n",
    "\n",
    "    bad = s >= 1\n",
    "    while np.any(bad):\n",
    "        u1[bad] = np.random.rand(np.sum(bad))\n",
    "        u2[bad] = np.random.rand(np.sum(bad))\n",
    "        x = 2 * u1 - 1\n",
    "        y = 2 * u2 - 1\n",
    "        s = x**2 + y**2\n",
    "        bad = s >= 1\n",
    "\n",
    "    z0 = x * np.sqrt(- 2 * np.log(s) / s)\n",
    "    z1 = y * np.sqrt(- 2 * np.log(s) / s)\n",
    "    z = np.column_stack((z0, z1))\n",
    "    \n",
    "    matrix = np.linalg.cholesky(covariance)\n",
    "    res = np.dot(z, matrix) + mean\n",
    "    \n",
    "    return res\n",
    "\n",
    "    \n",
    "def sample_histogram():\n",
    "    \n",
    "    mean = np.array([4, 7])\n",
    "    covariance = np.array([[20, -4], [-4, 40]])\n",
    "    sample = box_muller(mean, covariance)\n",
    "    \n",
    "    sample_mean = np.mean(sample, axis = 0)\n",
    "    sample_covariance = np.cov(sample, rowvar = False)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize = (15, 5))\n",
    "    ax[0].hist2d(sample[:, 0], sample[:, 1], bins = 30)\n",
    "    ax[0].axis('equal')\n",
    "    ax[1].hist(sample[:, 0], bins = 30)\n",
    "    ax[2].hist(sample[:, 1], bins = 30)\n",
    "    ax[0].set_title(\"2d histogram\")\n",
    "    ax[1].set_title(\"histogram of x\")\n",
    "    ax[2].set_title(\"histogram of y\")\n",
    "    plt.show()\n",
    "\n",
    "    print('sample mean = ', sample_mean, '\\n\\nsample covariance matrix =\\n', sample_covariance)\n",
    "    \n",
    "sample_histogram()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10*\n",
    "\n",
    "Implement a method of generating a random partition of an n-element set into subsets. Use it to estimate the expected number of subsets in a random partition of a set of 100 elements.\n",
    "\n",
    "Hint 1: Ширяев, Вероятность, т1, задача 2 к параграфу 1.\n",
    "\n",
    "Hint 2: http://djalil.chafai.net/blog/2012/05/03/generating-uniform-random-partitions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic distributions\n",
    "- **Uniform distribution $\\operatorname{U}[a, b]$**:\n",
    "$$p(x) = \\frac{1}{b-a}\\cdot\\mathbb{I}_{x\\in[a, b]}$$\n",
    "\n",
    "- **Exponential distribution $\\operatorname{Exp}(\\lambda)$**:\n",
    "$$p(x) = \\lambda e^{-\\lambda x}\\cdot\\mathbb{I}_{x\\geqslant0}$$\n",
    "\n",
    "- **Normal distribution $\\mathcal{N}(\\mu, \\sigma^2)$**:\n",
    "$$p(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$$\n",
    "\n",
    "- **Gamma distribution $\\operatorname{Gamma}(\\alpha, \\lambda)$**:\n",
    "$$p(x) = \\frac{\\lambda^\\alpha}{\\Gamma(\\alpha)}x^{\\alpha-1}e^{-\\lambda x}\\cdot\\mathbb{I}_{x\\geqslant0}$$\n",
    "\n",
    "- **Beta distribution $\\operatorname{Beta}(\\alpha, \\beta)$**:\n",
    "$$p(x) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)}x^{\\alpha-1}(1-x)^{\\beta-1}\\cdot\\mathbb{I}_{x\\in[0, 1]}$$\n",
    "\n",
    "- **$\\chi^2$ distribution with $k$ degrees of freedom $\\chi^2(k)$**:\n",
    "$$p(x) = \\frac{1}{2^{k/2}\\Gamma(k/2)}x^{k/2-1}e^{-x/2}\\cdot\\mathbb{I}_{x\\geqslant0}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define distributions and their parameters\n",
    "distributions = [\n",
    "    (\"Uniform distribution $\\\\operatorname{U}[-1, 1]$\", stats.uniform, (-1, 1)),\n",
    "    (\"Exponential distribution $\\\\operatorname{Exp}(1)$\", stats.expon, (1,)),\n",
    "    (\"Normal distribution $\\\\mathcal{N}(0, 1)$\", stats.norm, (0, 1)),\n",
    "    (\"Gamma distribution $\\\\operatorname{Gamma}(2, 2)$\", stats.gamma, (2, 2)),\n",
    "    (\"Beta distribution $\\\\operatorname{Beta}(2, 2)$\", stats.beta, (2, 2)),\n",
    "    (\"$\\\\chi^2$ distribution with $k$ degrees of freedom $\\\\chi^2(k)$\", stats.chi2, (5,))\n",
    "]\n",
    "\n",
    "# Setup the figure and axes for a 2x3 subplot\n",
    "fig, axs = plt.subplots(3, 2, figsize=(10, 15))  # Adjust figsize according to your needs\n",
    "axs = axs.flatten()  # Flatten the array to easily iterate over it\n",
    "\n",
    "for ax, (name, dist, params) in zip(axs, distributions):\n",
    "    # Generate sample data\n",
    "    data = dist.rvs(*params, size=1000)\n",
    "    # Generate points for PDF\n",
    "    x = np.linspace(min(data), max(data), 1000)\n",
    "    pdf = dist.pdf(x, *params)\n",
    "    \n",
    "    # Plot histogram of sample data\n",
    "    ax.hist(data, bins=30, density=True, alpha=0.5, label='Sample data')\n",
    "    # Plot theoretical PDF\n",
    "    ax.plot(x, pdf, 'r-', label='Theoretical PDF')\n",
    "    ax.set_title(name)\n",
    "    ax.legend()\n",
    "    ax.grid(linestyle='--', color='black', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()  # Adjust subplots to fit in the figure area\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
